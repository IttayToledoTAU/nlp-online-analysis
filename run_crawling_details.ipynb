{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 \\\n",
    "    (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_content_print_time(thread_id):\n",
    "    %time df_posts, df_users = page_content(thread_id)\n",
    "    return df_posts, df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_ids(pages, verbose=True):\n",
    "    print('Fetching pages...')\n",
    "    count = 0\n",
    "    base_main_url = 'https://www.fxp.co.il/forumdisplay.php?f=46&page=%d'\n",
    "    thread_ids = []\n",
    "    for i in pages:\n",
    "        main_url = base_main_url % i\n",
    "        response = requests.get(main_url)\n",
    "        contents = response.content.decode(\"utf-8\")\n",
    "        response.close()\n",
    "        currenct_thread_ids = re.findall(\"showthread\\.php\\?t=(.*)\\\" id=\", contents)\n",
    "        thread_ids +=  [int(x) for x in currenct_thread_ids]\n",
    "        count += 1\n",
    "        if verbose and (count % 10 == 0):\n",
    "            print('Fetched %s pages' % (count))\n",
    "            print(datetime.now().time())\n",
    "    thread_ids.remove(12069815)\n",
    "    return thread_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_content(thread_id):\n",
    "    df_thread_new = pd.DataFrame(columns=['thread_id', 'title'])\n",
    "    df_post_new = pd.DataFrame(columns=['thread_id', 'post_id','user_name','date','message',\n",
    "                                        'cite1','cite2','cite3','cite4'])\n",
    "    df_user_new = pd.DataFrame(columns=['user_name', 'register_date','message_count','signiture_text'])\n",
    "    page = 1\n",
    "    url='https://www.fxp.co.il/showthread.php?t=%s' % (thread_id)\n",
    "    response_page = None\n",
    "    while page == 1 or not response_page.history:\n",
    "        if page > 1:\n",
    "            url='https://www.fxp.co.il/showthread.php?t=%s&page=%s' % (thread_id,str(page))\n",
    "        response_page = requests.get(url)\n",
    "        content_page = response_page.content.decode(\"utf-8\")\n",
    "        if page == 1:\n",
    "            soup = BeautifulSoup(content_page, 'lxml')\n",
    "            title = title = soup.title.getText()\n",
    "            df_thread_new = df_thread_new.append({'thread_id':thread_id, 'title':title}, ignore_index=True)\n",
    "        df_post_new_, df_user_new_ = thread_single_page_content(thread_id, content_page, page)\n",
    "        df_post_new = pd.concat([df_post_new,df_post_new_])\n",
    "        df_user_new = pd.concat([df_user_new,df_user_new_])\n",
    "        page += 1\n",
    "    return df_thread_new, df_post_new, df_user_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_single_page_content(thread_id, contents, page):\n",
    "    df_post_new = pd.DataFrame(columns=['thread_id', 'post_id','user_name','date','message',\n",
    "                                        'cite1','cite2','cite3','cite4'])\n",
    "    df_user_new = pd.DataFrame(columns=['user_name', 'register_date','message_count','signiture_text'])\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    posts = soup.find_all(id=re.compile('^post_[0-9].*'))\n",
    "    for post in posts:\n",
    "        post_id = post.get('id').replace('_','')\n",
    "        message = post.find('blockquote', {'class': 'postcontent restore'}).getText().strip()\n",
    "        try:\n",
    "            user_name = post.find('a', {'class': re.compile('username .* popupctrl')}).findChildren(\"span\" , recursive=True)[0].getText()\n",
    "        except:\n",
    "            user_name = post.find('a', {'class': re.compile('username .* popupctrl')}).findChildren(\"strong\" , recursive=True)[0].getText()\n",
    "            #post_counter = post.find('a', {'class': 'postcounter'}).getText()\n",
    "            #print(f'Error in thread: {thread_id} ,page: {page} in {message} {post_counter}')\n",
    "        message_date = post.find('span', {'class': 'date'}).getText()\n",
    "        cites = post.find_all('div', {'class': 'bbcode_quote'})\n",
    "        cited_post = []\n",
    "        for cite in cites:\n",
    "            for c in cites:\n",
    "                try:\n",
    "                    link = c.find('a')['href']\n",
    "                    cited_post.append(link[link.find('#')+1:])\n",
    "                except:\n",
    "                    cited_post.append('custom cites')\n",
    "        user_details = post.find('dl', {'class': 'userstats-new'}).find_all('dd')\n",
    "        user_reg_date = user_details[0].getText()\n",
    "        user_message_count = user_details[1].getText()\n",
    "        try:\n",
    "            signiture_text = post.find('blockquote', {'class': 'signature restore'}).getText()\n",
    "        except:\n",
    "            signiture_text = ''\n",
    "        df_post_new = df_post_new.append({'thread_id': thread_id, 'post_id': post_id,'user_name': user_name,'date':message_date,\n",
    "                            'message': message,'cite1':cited_post[0] if len(cites) > 0 else '',\n",
    "                            'cite2': cited_post[1] if len(cites) > 1 else '', \n",
    "                            'cite3': cited_post[2] if len(cites) > 2 else '',\n",
    "                            'cite4': cited_post[3] if len(cites) > 3 else ''}, ignore_index=True)\n",
    "        df_user_new = df_user_new.append({'user_name': user_name, 'register_date': user_reg_date, 'message_count': user_message_count, 'signiture_text': signiture_text}, ignore_index=True)\n",
    "    return df_post_new, df_user_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_content(thread_ids, thread_file='thread.csv', post_file='post.csv', user_file='user.csv',verbose=True):\n",
    "    print('Fetching threads...')\n",
    "    count = 0\n",
    "    df_thread_new = pd.DataFrame(columns=['thread_id', 'title','type'])\n",
    "    df_post_new = pd.DataFrame(columns=['thread_id', 'post_id','user_name','date','message',\n",
    "                                        'cite1','cite2','cite3','cite4'])\n",
    "    df_user_new = pd.DataFrame(columns=['user_name', 'register_date','message_count','signiture_text'])\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=None) as executor:\n",
    "        future_to_url = {executor.submit(page_content, thread_id): thread_id for thread_id in thread_ids}\n",
    "        print(f'finish to submit all jobs')\n",
    "        df = pd.DataFrame(columns=['thread', 'post'])\n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            df_thread_new_, df_post_new_, df_user_new_=future.result()\n",
    "            df_thread_new = pd.concat([df_thread_new,df_thread_new_])\n",
    "            df_post_new = pd.concat([df_post_new,df_post_new_])\n",
    "            df_user_new = pd.concat([df_user_new,df_user_new_])\n",
    "    df_thread_new.to_csv(thread_file, encoding='utf-8')        \n",
    "    df_post_new.to_csv(post_file, encoding='utf-8')        \n",
    "    df_user_new.to_csv(user_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pages...\n",
      "Fetching threads...\n",
      "finish to submit all jobs\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%time thread_content(thread_ids(range(1, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
